{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wav data to keras dataset\n",
    "import numpy as np\n",
    "from keras.utils import audio_dataset_from_directory\n",
    "\n",
    "# Load audio dataset from directory\n",
    "train_dataset, validation_dataset = audio_dataset_from_directory(\n",
    "    directory='data/path/train',\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    seed=1337,\n",
    "    batch_size=64,\n",
    "    output_sequence_length=16000, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from transformers import AutoFeatureExtractor, TFWav2Vec2ForSequenceClassification\n",
    "\n",
    "# Load pre-trained Wav2Vec2 model and processor using AutoFeatureExtractor\n",
    "model_name = \"facebook/wav2vec2-base-960h\"\n",
    "tokenizer = AutoFeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "# Load pre-trained Wav2Vec2 model\n",
    "model = TFWav2Vec2ForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoFeatureExtractor\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Load Wav2Vec tokenizer\n",
    "model_name = \"facebook/wav2vec2-base-960h\"\n",
    "tokenizer = AutoFeatureExtractor.from_pretrained(model_name)\n",
    "print(\"test\")\n",
    "\n",
    "# Define a function to tokenize audio data\n",
    "def tokenize_dataset(dataset):\n",
    "    tokenized_batches = []\n",
    "    for batch in tqdm(dataset, total=len(dataset)):\n",
    "        \n",
    "        audio_batch, labels = batch\n",
    "        # print(audio_batch)\n",
    "        inputs = tokenizer(audio_batch, return_tensors=\"tf\", padding=True, verbose=False, sampling_rate=16000)\n",
    "        tokenized_batches.append((inputs.input_values, labels))\n",
    "    return tokenized_batches\n",
    "\n",
    "# Tokenize the train dataset\n",
    "tokenized_train_dataset = tokenize_dataset(train_dataset)\n",
    "\n",
    "# Tokenize the validation dataset\n",
    "tokenized_validation_dataset = tokenize_dataset(validation_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Convert tokenized batches into a generator function\n",
    "def batch_generator(tokenized_batches):\n",
    "    for input_values, labels in tokenized_batches:\n",
    "        yield input_values, labels\n",
    "\n",
    "# Create Keras batch datasets for train and validation datasets\n",
    "keras_train_dataset = tf.data.Dataset.from_generator(\n",
    "    generator=lambda: batch_generator(tokenized_train_dataset),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(1, 32, 16000, 1), dtype=tf.float32),  # Input values\n",
    "        tf.TensorSpec(shape=(32, 30), dtype=tf.int32)           # Labels\n",
    "    )\n",
    ")\n",
    "\n",
    "keras_validation_dataset = tf.data.Dataset.from_generator(\n",
    "    generator=lambda: batch_generator(tokenized_validation_dataset),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(1, 32, 16000, 1), dtype=tf.float32),  # Input values\n",
    "        tf.TensorSpec(shape=(32, 30), dtype=tf.int32)           # Labels\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.concat([i[0][0] for i in tokenized_train_dataset], axis=0)\n",
    "X_val = tf.concat([i[0][0] for i in tokenized_validation_dataset], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.concat([i[1] for i in tokenized_train_dataset], axis=0)\n",
    "y_val = tf.concat([i[1] for i in tokenized_validation_dataset], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.numpy()\n",
    "X_val = X_val.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Dropout, Dense\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, TimeDistributed\n",
    "\n",
    "\n",
    "def get_SR_Model(num_classes: int):\n",
    "    X_input = Input(shape=(16000, 1))\n",
    "    X = Conv1D(filters=256,kernel_size=15,strides=4)(X_input)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = Conv1D(filters=512,kernel_size=15,strides=4)(X_input)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = LSTM(units=512, return_sequences=True)(X)\n",
    "    X = LSTM(units=512, return_sequences=False)(X)\n",
    "    X = Dense(num_classes, activation='softmax')(X)\n",
    "    return Model(inputs=[X_input], outputs=[X])\n",
    "\n",
    "model = get_SR_Model(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from transformers import TFWav2Vec2Model\n",
    "from tensorflow.keras import Model, layers\n",
    "\n",
    "\n",
    "class TFWav2Vec2Layer(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(TFWav2Vec2Layer, self).__init__(**kwargs)\n",
    "        self.wav2vec_model = TFWav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "        self.wav2vec_model.trainable = False\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return self.wav2vec_model(inputs)[\"last_hidden_state\"]\n",
    "\n",
    "\n",
    "def get_wav2vec_classifier(num_classes: int):\n",
    "    # Define input layer for tokenized input\n",
    "    tokenized_input = layers.Input(shape=(None,), dtype=tf.int32)\n",
    "\n",
    "    # Pass input through custom Wav2Vec2 layer\n",
    "    hidden_states = TFWav2Vec2Layer()(tokenized_input)\n",
    "\n",
    "    # Add classification layers\n",
    "    x = layers.Dense(512, activation='relu')(hidden_states[:, 0, :])  # Take the first token's representation\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Define model\n",
    "    model = Model(inputs=tokenized_input, outputs=x)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "model = get_wav2vec_classifier(num_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                loss=losses.CategoricalCrossentropy(),\n",
    "                metrics=[metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
